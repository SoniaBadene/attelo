{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers (part 2)\n",
    "\n",
    "In the previous tutorial, we saw a couple of basic parsers, and also introduced the notion of a pipeline parser.  It turns out that some of the parsers we introduced and had taken for granted are themselves pipelines.  In this tutorial we will break these pipelines down and explore some of finer grained tasks that a parser can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "We begin with the same multipacks and the same breakdown into a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading edus and pairings... done [1 ms]\n",
      "Reading features... done [1 ms]\n",
      "Build data packs... done [0 ms]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from os import path as fp\n",
    "from attelo.io import (load_multipack)\n",
    "\n",
    "CORPUS_DIR = 'example-corpus'\n",
    "PREFIX = fp.join(CORPUS_DIR, 'tiny')\n",
    "\n",
    "# load the data into a multipack\n",
    "mpack = load_multipack(PREFIX + '.edus',\n",
    "                       PREFIX + '.pairings',\n",
    "                       PREFIX + '.features.sparse',\n",
    "                       PREFIX + '.features.sparse.vocab',\n",
    "                       verbose=True)\n",
    "\n",
    "test_dpack = mpack.values()[0]\n",
    "train_mpack = {k: mpack[k] for k in mpack.keys()[1:]}\n",
    "train_dpacks = train_mpack.values()\n",
    "train_targets = [x.target for x in train_dpacks]\n",
    "\n",
    "def print_results(dpack):\n",
    "    'summarise parser results'\n",
    "    for i, (edu1, edu2) in enumerate(dpack.pairings):\n",
    "        wanted = dpack.get_label(dpack.target[i])\n",
    "        got = dpack.get_label(dpack.graph.prediction[i])\n",
    "        print(i, edu1.id, edu2.id, '\\t|', got, '\\twanted:', wanted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking a parser down (attach)\n",
    "\n",
    "If we examine the [source code for the attach pipeline](https://github.com/irit-melodi/attelo/blob/master/attelo/parser/attach.py), we can see that it is in fact a two step pipeline combining the attach classifier wrapper and a decoder. So let's see what happens when we run the attach classifier by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ROOT d2_e2 \t| 0.44 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "1 d2_e3 d2_e2 \t| 0.43 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "2 d2_e4 d2_e2 \t| 0.43 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "3 ROOT d2_e3 \t| 0.44 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "4 d2_e2 d2_e3 \t| 0.97 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "5 d2_e4 d2_e3 \t| 0.39 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "6 ROOT d2_e4 \t| 0.01 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "7 d2_e3 d2_e4 \t| 0.42 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "8 d2_e2 d2_e4 \t| 0.39 [ 1.  1.  1.  1.  1.  1.] __UNK__\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from attelo.learning import (SklearnAttachClassifier)\n",
    "from attelo.parser.attach import (AttachClassifierWrapper)\n",
    "from sklearn.linear_model import (LogisticRegression)\n",
    "\n",
    "def print_results_verbose(dpack):\n",
    "    \"\"\"Print detailed parse results\"\"\"\n",
    "    for i, (edu1, edu2) in enumerate(dpack.pairings):\n",
    "        attach = \"{:.2f}\".format(dpack.graph.attach[i])\n",
    "        label = np.around(dpack.graph.label[i,:], decimals=2)\n",
    "        got = dpack.get_label(dpack.graph.prediction[i])\n",
    "        print(i, edu1.id, edu2.id, '\\t|', attach, label, got)\n",
    "        \n",
    "learner = SklearnAttachClassifier(LogisticRegression())\n",
    "parser1a = AttachClassifierWrapper(learner)\n",
    "parser1a.fit(train_dpacks, train_targets)\n",
    "\n",
    "dpack = parser1a.transform(test_dpack)\n",
    "print_results_verbose(dpack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsers and weighted datapacks\n",
    "\n",
    "In the output above, we have dug a little bit deeper into our datapacks. Recall above that a parser translates datapacks to datapacks. The output of a parser is always a *weighted datapack*., ie. a datapack whose 'graph'\n",
    "attribute is set to a record containing\n",
    "\n",
    "* attachment weights\n",
    "* label weights\n",
    "* predictions (like target values)\n",
    "\n",
    "So called \"standalone\" parsers will take an unweighted datapack (`graph == None`) and produce a weighted datapack with predictions set. But some parsers tend to be more useful as part of a pipeline:\n",
    "\n",
    "* the attach classfier wrapper fills the attachment weights\n",
    "* likewise the label classifier wrapper assigns label weights\n",
    "* a decoder assigns predictions from weights\n",
    "\n",
    "We see the first case in the above output. Notice that the attachments have been set to values from a model, but the label weights and predictions are assigned default values.  \n",
    "\n",
    "NB: all parsers should do \"something sensible\" in the face of all inputs. This typically consists of assuming the default weight of 1.0 for unweighted datapacks.\n",
    "\n",
    "### Decoders\n",
    "\n",
    "Having now transformed a datapack with the attach classifier wrapper, let's now pass its results to a decoder.  In fact, let's try a couple of different decoders and compare the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ROOT d2_e2 \t| 0.44 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "1 d2_e3 d2_e2 \t| 0.43 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "2 d2_e4 d2_e2 \t| 0.43 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "3 ROOT d2_e3 \t| 0.44 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "4 d2_e2 d2_e3 \t| 0.97 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "5 d2_e4 d2_e3 \t| 0.39 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "6 ROOT d2_e4 \t| 0.01 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "7 d2_e3 d2_e4 \t| 0.42 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "8 d2_e2 d2_e4 \t| 0.39 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n"
     ]
    }
   ],
   "source": [
    "from attelo.decoding.baseline import (LocalBaseline)\n",
    "\n",
    "decoder = LocalBaseline(threshold=0.4)\n",
    "dpack2 = decoder.transform(dpack)\n",
    "print_results_verbose(dpack2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above is what we get if we run a decoder on the output of the attach classifier wrapper.  This is in fact, the the same thing as running the attachment pipeline.  We can define a similar pipeline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ROOT d2_e2 \t| 0.44 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "1 d2_e3 d2_e2 \t| 0.43 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "2 d2_e4 d2_e2 \t| 0.43 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "3 ROOT d2_e3 \t| 0.44 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "4 d2_e2 d2_e3 \t| 0.97 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "5 d2_e4 d2_e3 \t| 0.39 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "6 ROOT d2_e4 \t| 0.01 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n",
      "7 d2_e3 d2_e4 \t| 0.42 [ 1.  1.  1.  1.  1.  1.] __UNK__\n",
      "8 d2_e2 d2_e4 \t| 0.39 [ 1.  1.  1.  1.  1.  1.] UNRELATED\n"
     ]
    }
   ],
   "source": [
    "from attelo.parser.pipeline import (Pipeline)\n",
    "\n",
    "# this is basically attelo.parser.attach.AttachPipeline\n",
    "parser1 = Pipeline(steps=[('attach weights', parser1a),\n",
    "                          ('decoder', decoder)])\n",
    "parser1.fit(train_dpacks, train_targets)\n",
    "print_results_verbose(parser1.transform(test_dpack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing and matching\n",
    "\n",
    "Being able to break parsing down to this level of granularity lets us experiment with parsing techniques by composing different parsing substeps in different ways.  For example, below, we write two slightly different pipelines, one which sets labels separately from decoding, and one which combines attach and label scores before handing them off to a decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-labelling\n",
      "--------------\n",
      "0 ROOT d2_e2 \t| 0.44 [ 0.    0.45  0.28  0.28  0.    0.  ] elaboration\n",
      "1 d2_e3 d2_e2 \t| 0.43 [ 0.    0.4   0.34  0.25  0.    0.  ] elaboration\n",
      "2 d2_e4 d2_e2 \t| 0.43 [ 0.    0.3   0.53  0.17  0.    0.  ] narration\n",
      "3 ROOT d2_e3 \t| 0.44 [ 0.    0.45  0.28  0.28  0.    0.  ] elaboration\n",
      "4 d2_e2 d2_e3 \t| 0.97 [ 0.    0.52  0.03  0.45  0.    0.  ] elaboration\n",
      "5 d2_e4 d2_e3 \t| 0.39 [ 0.    0.37  0.43  0.2   0.    0.  ] UNRELATED\n",
      "6 ROOT d2_e4 \t| 0.01 [ 0.    0.45  0.28  0.28  0.    0.  ] UNRELATED\n",
      "7 d2_e3 d2_e4 \t| 0.42 [ 0.    0.41  0.35  0.24  0.    0.  ] elaboration\n",
      "8 d2_e2 d2_e4 \t| 0.39 [ 0.    0.37  0.43  0.2   0.    0.  ] UNRELATED\n",
      "\n",
      "Joint\n",
      "-----\n",
      "0 ROOT d2_e2 \t| 0.19 [ 0.    0.45  0.28  0.28  0.    0.  ] UNRELATED\n",
      "1 d2_e3 d2_e2 \t| 0.17 [ 0.    0.4   0.34  0.25  0.    0.  ] UNRELATED\n",
      "2 d2_e4 d2_e2 \t| 0.23 [ 0.    0.3   0.53  0.17  0.    0.  ] UNRELATED\n",
      "3 ROOT d2_e3 \t| 0.19 [ 0.    0.45  0.28  0.28  0.    0.  ] UNRELATED\n",
      "4 d2_e2 d2_e3 \t| 0.50 [ 0.    0.52  0.03  0.45  0.    0.  ] elaboration\n",
      "5 d2_e4 d2_e3 \t| 0.17 [ 0.    0.37  0.43  0.2   0.    0.  ] UNRELATED\n",
      "6 ROOT d2_e4 \t| 0.00 [ 0.    0.45  0.28  0.28  0.    0.  ] UNRELATED\n",
      "7 d2_e3 d2_e4 \t| 0.17 [ 0.    0.41  0.35  0.24  0.    0.  ] UNRELATED\n",
      "8 d2_e2 d2_e4 \t| 0.17 [ 0.    0.37  0.43  0.2   0.    0.  ] UNRELATED\n"
     ]
    }
   ],
   "source": [
    "from attelo.learning.local import (SklearnLabelClassifier)\n",
    "from attelo.parser.label import (LabelClassifierWrapper, \n",
    "                                 SimpleLabeller)\n",
    "from attelo.parser.full import (AttachTimesBestLabel)\n",
    "\n",
    "learner_l = SklearnLabelClassifier(LogisticRegression())\n",
    "\n",
    "print(\"Post-labelling\")\n",
    "print(\"--------------\")\n",
    "parser = Pipeline(steps=[('attach weights', parser1a),\n",
    "                         ('decoder', decoder),\n",
    "                         ('labels', SimpleLabeller(learner_l))])\n",
    "parser.fit(train_dpacks, train_targets)\n",
    "print_results_verbose(parser.transform(test_dpack))\n",
    "\n",
    "print()\n",
    "print(\"Joint\")\n",
    "print(\"-----\")\n",
    "parser = Pipeline(steps=[('attach weights', parser1a),\n",
    "                         ('label weights', LabelClassifierWrapper(learner_l)),\n",
    "                         ('attach times label', AttachTimesBestLabel()),\n",
    "                         ('decoder', decoder)])\n",
    "parser.fit(train_dpacks, train_targets)\n",
    "print_results_verbose(parser.transform(test_dpack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Thinking of parsers as transformers from weighted datapacks to weighted datapacks should allow for some interesting parsing experiments, parsers that\n",
    "\n",
    "* divide the work using different strategies on different subtypes of input (eg. intra vs intersentential links), or\n",
    "* work in multiple stages, maybe modifying past decisions along the way, or\n",
    "* influence future parsing stages by tweaking the weights they might see, or\n",
    "* prune out undesirable edges (by setting their weights to zero), or\n",
    "* apply some global constraint satisfaction algorithm across the possible weights\n",
    "\n",
    "With a notion of a parsing pipeline, you should also be able to build parsers that combine different experiments that you want to try simultaneously"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
